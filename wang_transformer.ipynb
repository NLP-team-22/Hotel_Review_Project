{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20491, 100)\n",
      "[[  217   215    52   228   412  1612    11    26     8   114    10   403\n",
      "   4327  1497   728    10    54  2047  8400     2    27    11  3632     2\n",
      "     66   722   256   688   401     6  3514   297   926   960  1083   100\n",
      "   2207    16    23  4647  3040    10   650  4507    99    87  5425    99\n",
      "    271  2113 17985  3919  4327    34 18387  1984  1591   462   531  1590\n",
      "    390   351    11 51415  4565    39   212  8310   950 51416   960   470\n",
      "    623    34    62  4776  2175   934 15879   676  1224  4776    10  1022\n",
      "   2257   471    13   720  2328   139    27   208   218     2    51     3\n",
      "      6   271   150  2315]\n",
      " [ 2622  2674 16577    10    36    17     8 16577   710   313   859   180\n",
      "   3599   240  4830  1468    24  5941    39  3999  2515   524   260  1024\n",
      "     60  1094  3112   489     1    53     2   227   318    13  2509  2302\n",
      "     36    79     9     5 17646  4237    26   706    22   191    20     7\n",
      "     27    31   198     5  1086    21   117   229     5    54 38957   357\n",
      "   1524   502 16577     6   601   134     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]]\n",
      "Epoch 1/5\n",
      "1640/1640 [==============================] - 17s 9ms/step - loss: 1.0147 - accuracy: 0.5561 - val_loss: 0.8604 - val_accuracy: 0.6250\n",
      "Epoch 2/5\n",
      "1640/1640 [==============================] - 14s 8ms/step - loss: 0.7183 - accuracy: 0.6947 - val_loss: 0.9108 - val_accuracy: 0.6226\n",
      "Epoch 3/5\n",
      "1640/1640 [==============================] - 14s 9ms/step - loss: 0.5549 - accuracy: 0.7756 - val_loss: 1.0056 - val_accuracy: 0.6040\n",
      "Epoch 4/5\n",
      "1640/1640 [==============================] - 15s 9ms/step - loss: 0.4088 - accuracy: 0.8449 - val_loss: 1.2802 - val_accuracy: 0.5975\n",
      "Epoch 5/5\n",
      "1640/1640 [==============================] - 14s 9ms/step - loss: 0.2773 - accuracy: 0.9020 - val_loss: 1.6199 - val_accuracy: 0.5753\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/unprocessed/tripadvisor_hotel_reviews.csv')\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Review'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['Review'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "\n",
    "padded_sequences = padded_sequences[:, :100]  # limit the size to 100 tokens for now\n",
    "\n",
    "max_seq_length = 100\n",
    "\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['Rating'], test_size=0.2, random_state=22)\n",
    "\n",
    "# make scores 0 to 4 instead of 1 to 5\n",
    "y_train -= 1\n",
    "y_test -= 1\n",
    "\n",
    "print(X_train[:2])\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), \n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "\n",
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = Input(shape=(max_seq_length,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_seq_length, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=10, epochs=5, \n",
    "                    validation_data=(X_test, y_test)\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 - 1s - loss: 1.6199 - accuracy: 0.5753 - 524ms/epoch - 4ms/step\n",
      "loss: 1.620\n",
      "accuracy: 0.575\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 7th, 8th and 9th mock reviews were taken from recent trip advisor reviews (not in the dataset), and ratings were 2, 1, 3 respectively.\n",
    "\n",
    "The following block of code will predict the ratings in the mock_reviews and print out a list of the predicted ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[3.667477898299694, 1.007367304426225, 1.0028702747229659, 3.0528145637363195, 1.0128547379540578, 3.849524668585218, 1.9782704779809137, 1.9600387723257882, 2.015419053393657, 4.127005843445659]\n"
     ]
    }
   ],
   "source": [
    "mock_reviews = pd.Series(\n",
    "    [ \n",
    "        \"The staff was friendly!\",\n",
    "        \"The service was horrible!\",\n",
    "        \"The hotel is dirty!\",\n",
    "        \"The location is convenient.\",\n",
    "        \"The elevator was broken\",\n",
    "        \"exciting views.\",\n",
    "        \"I travel for work in wind energy field. This is the closest motel. Worth driving 20 miles further for a clean comfortable room. This is the 3rd stay. Due to having to be at the windfarm early, we stayed. This room was in the older building. Uncomfortable beds, dingy bedding. I had to go buy Lysol to spray. If you have allergies, stay away. Shower curtain has mold all along bottom. I guess they don't know what bleach is. I don't usually post negative reviews, but felt need to. Also, overcharged. 79.00 for 30.00 room. The newer building was not much better.\",\n",
    "        \"Do not eat at the buffet. We went on NYE there was barely any food and what was there was old. It consisted of ham, a couple pieces of friend chicken, white rice , and corn on cob that I couldnâ€™t even eat it tasted so bad. I scraped the bottom of the lettuce bowl for a salad and got one chicken breast on NYE. We went back the next morning for breakfast(as this is the only place to eat on site) and never got our food after waiting for 30 minutes with only 4 tables full in the place. All the other tables waited longer and got cold food and runny pancakes. I saw two tables walk out during our wait. I watched a burrito sit in the window the entire time we were there. The waitress told us we could refill our own drinks as she was so busy. There were 3 people working at the time and again 4 tables only of customers.\",\n",
    "        \"We stayed for a 3 day weekend in May. Hotel is decent for the area and the price. People were friendly. Big refrigerator, microwave and coffee maker in the room. Bed was comfortable and the shower was good. \\\n",
    "        No real closet - just a rod in the room to hang things on. No safe so I had to take my laptop with me everywhere I went. Do not like just leaving it in the room. \\\n",
    "        Casino hours very weird. They open table games at 4pm. We were there on Thursday night around 8:30pm. Only 2 tables open - blackjack and 3 card poker. \\\n",
    "        My husband arrived around 9:30 to join me. At 10pm the dealer tells us they are closing the tables since it is a week night. So early! On Friday we didn't\\\n",
    "        get there until around 10:15. The night before the pit boss told us the tables stay open on Friday and Saturday until sometime between midnight and 2am\\\n",
    "         depending on how busy they are so we thought we would be able to play for awhile. At 10:45pm they shut the tables down. So weird! Also - sign on the wall\\\n",
    "           says if you win a jackpot on the slot machines that is $1200 or more you have to have your drivers license AND social security card. Who carries their social security card with them!\",\n",
    "        \"The best hotel I have ever seen!\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_mock = pad_sequences(tokenizer.texts_to_sequences(mock_reviews), maxlen=max_seq_length, padding='post')\n",
    "result_list = model.predict(x_mock)\n",
    "numerical_result = []\n",
    "for result in result_list:\n",
    "    rating = 0\n",
    "    for i in range(5):\n",
    "        rating += result[i] * (i + 1)\n",
    "    numerical_result.append(rating)\n",
    "print(numerical_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
