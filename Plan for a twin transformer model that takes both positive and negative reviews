
The only problem of the new dataset is that it only comes with separated the good and negative reviews and doesn't have a combined version, which means we wouldn't be able to train a model that giving a description could output stuff. 
But I think I do have an idea to solve this problem. We can train a model that does sentimental analysis to seperate each review into positive and negative sentences. call that model 1.
After we train model 1, we use model 1 to seperate any inputs into positve and negative. And then we train a "twin stream" transformer model that combines the positive and negative transformer. So that when deployed, we could write any review and model 1 will separate it into negative and positive and then model 2 will do the prediction.

If we would like to go in that direction we could split the work up.


1. Making a new data set with two columns, 1st columns are all the reviews (both positive and negative) from the new data set, and 2nd column indicates whether it is positive or negative. 1 for positive 2 for negative.

2. Change the model so that the output layer just output two classes. This will be our model 1.

3. Change the new dataset so that the "No Negative" and "No Positive" becomes empty string "".

4. Change the model to a twin transformer so that it takes to inputs and will join the result at the final feed forward layer with classification output of 100 classes (0.1 increasement being a single class, from 0 to 10).

5. Make a preprocessing function that using model 1 to turn a single review into two review, one positive and one negative. By putting the sentences that model predicts as negative to one review and the rest to the other. 
